{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [83.50099208567403]\n",
      "Mean accuracy across runs :  83.50099208567403\n",
      "Mean Acc for thrashed classes : 57.760000991821286\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "runs   = [\n",
    "            \"MT_Baseline_cbd6a1526138615c68153f5e5e57a692/Metrics\"\n",
    "        ]   \n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_food101_val_test_empirical_c79af0294f8e78f4a8b0793248cc788b.pkl\",\n",
    "              ]\n",
    "\n",
    "dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets/df_food101_val_test.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis for entire val set\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy']['best'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   \n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "\n",
    "df_thrashed = df_base[df_base['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>44.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>61.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>46.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>61.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>81.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>47.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>70.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>52.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>57.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  accuracy_0\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   44.400002\n",
       "beignets/847393.jpg                     Beignets      6   54.000000\n",
       "churros/274692.jpg                       Churros     23   61.600002\n",
       "sashimi/3686273.jpg                      Sashimi     86   46.400002\n",
       "pho/163128.jpg                               Pho     75   61.600002\n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   81.599998\n",
       "takoyaki/3609028.jpg                    Takoyaki     97   47.200001\n",
       "clam_chowder/770062.jpg             Clam chowder     24   70.800003\n",
       "onion_rings/3494133.jpg              Onion rings     68   52.799999\n",
       "lobster_bisque/378185.jpg         Lobster bisque     60   57.200001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base[df_base['class'].isin(thrashed_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [84.40792272586634]\n",
      "Mean accuracy across runs :  84.40792272586634\n",
      "Mean Acc for thrashed classes : 64.48000068664551\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>21.582735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>23.478260</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>17.708332</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.200005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>14.925373</td>\n",
       "      <td>25.0</td>\n",
       "      <td>51.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>32.291664</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>26.086956</td>\n",
       "      <td>50.0</td>\n",
       "      <td>84.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>28.030302</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>9.589041</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>22.881357</td>\n",
       "      <td>50.0</td>\n",
       "      <td>63.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>18.691589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  dhard_accs  \\\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   21.582735   \n",
       "beignets/847393.jpg                     Beignets      6   23.478260   \n",
       "churros/274692.jpg                       Churros     23   17.708332   \n",
       "sashimi/3686273.jpg                      Sashimi     86   14.925373   \n",
       "pho/163128.jpg                               Pho     75   32.291664   \n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   26.086956   \n",
       "takoyaki/3609028.jpg                    Takoyaki     97   28.030302   \n",
       "clam_chowder/770062.jpg             Clam chowder     24    9.589041   \n",
       "onion_rings/3494133.jpg              Onion rings     68   22.881357   \n",
       "lobster_bisque/378185.jpg         Lobster bisque     60   18.691589   \n",
       "\n",
       "                               dhard_sub_accs  accuracy_best_0  \n",
       "french_onion_soup/2993508.jpg             0.0        52.799999  \n",
       "beignets/847393.jpg                      75.0        62.799999  \n",
       "churros/274692.jpg                       75.0        67.200005  \n",
       "sashimi/3686273.jpg                      25.0        51.600002  \n",
       "pho/163128.jpg                           25.0        70.000000  \n",
       "hot_and_sour_soup/1864685.jpg            50.0        84.800003  \n",
       "takoyaki/3609028.jpg                     25.0        60.000000  \n",
       "clam_chowder/770062.jpg                  50.0        69.599998  \n",
       "onion_rings/3494133.jpg                  50.0        63.200001  \n",
       "lobster_bisque/378185.jpg                 0.0        62.799999  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 21.526560974121093\n",
      "Mean dhard_sub performance 37.5\n",
      "Mean acc_improvement 64.48000068664551\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [84.59406110555818]\n",
      "Mean accuracy across runs :  84.59406110555818\n",
      "Mean Acc for thrashed classes : 63.92000122070313\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    " \"MT_Augmented_59c0f4b687d5480aad36ae2c6725879b/Metrics/\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>23.021584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>19.130434</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>26.041666</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>26.119402</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>26.086956</td>\n",
       "      <td>50.0</td>\n",
       "      <td>84.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>23.484848</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>17.808220</td>\n",
       "      <td>75.0</td>\n",
       "      <td>73.200005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>21.186441</td>\n",
       "      <td>50.0</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>16.822430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.600002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  dhard_accs  \\\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   23.021584   \n",
       "beignets/847393.jpg                     Beignets      6   19.130434   \n",
       "churros/274692.jpg                       Churros     23   26.041666   \n",
       "sashimi/3686273.jpg                      Sashimi     86   26.119402   \n",
       "pho/163128.jpg                               Pho     75   14.583333   \n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   26.086956   \n",
       "takoyaki/3609028.jpg                    Takoyaki     97   23.484848   \n",
       "clam_chowder/770062.jpg             Clam chowder     24   17.808220   \n",
       "onion_rings/3494133.jpg              Onion rings     68   21.186441   \n",
       "lobster_bisque/378185.jpg         Lobster bisque     60   16.822430   \n",
       "\n",
       "                               dhard_sub_accs  accuracy_best_0  \n",
       "french_onion_soup/2993508.jpg             0.0        53.200001  \n",
       "beignets/847393.jpg                      75.0        61.200001  \n",
       "churros/274692.jpg                       75.0        70.800003  \n",
       "sashimi/3686273.jpg                      50.0        59.200001  \n",
       "pho/163128.jpg                           25.0        56.799999  \n",
       "hot_and_sour_soup/1864685.jpg            50.0        84.400002  \n",
       "takoyaki/3609028.jpg                     25.0        56.799999  \n",
       "clam_chowder/770062.jpg                  75.0        73.200005  \n",
       "onion_rings/3494133.jpg                  50.0        62.000000  \n",
       "lobster_bisque/378185.jpg                 0.0        61.600002  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 21.42853136062622\n",
      "Mean dhard_sub performance 42.5\n",
      "Mean acc_improvement 63.92000122070313\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [84.26534766017801]\n",
      "Mean accuracy across runs :  84.26534766017801\n",
      "Mean Acc for thrashed classes : 62.3200008392334\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    \"MT_Augmented_719e4237edc6f64e59d0c8884bf81f01/Metrics\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>20.143887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>20.869564</td>\n",
       "      <td>75.0</td>\n",
       "      <td>60.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>16.666666</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.200005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>14.179104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>19.565216</td>\n",
       "      <td>50.0</td>\n",
       "      <td>81.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>29.545454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>13.698630</td>\n",
       "      <td>75.0</td>\n",
       "      <td>72.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>23.728813</td>\n",
       "      <td>25.0</td>\n",
       "      <td>63.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>10.280374</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  dhard_accs  \\\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   20.143887   \n",
       "beignets/847393.jpg                     Beignets      6   20.869564   \n",
       "churros/274692.jpg                       Churros     23   16.666666   \n",
       "sashimi/3686273.jpg                      Sashimi     86   14.179104   \n",
       "pho/163128.jpg                               Pho     75   14.583333   \n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   19.565216   \n",
       "takoyaki/3609028.jpg                    Takoyaki     97   29.545454   \n",
       "clam_chowder/770062.jpg             Clam chowder     24   13.698630   \n",
       "onion_rings/3494133.jpg              Onion rings     68   23.728813   \n",
       "lobster_bisque/378185.jpg         Lobster bisque     60   10.280374   \n",
       "\n",
       "                               dhard_sub_accs  accuracy_best_0  \n",
       "french_onion_soup/2993508.jpg             0.0        52.000000  \n",
       "beignets/847393.jpg                      75.0        60.799999  \n",
       "churros/274692.jpg                       75.0        67.200005  \n",
       "sashimi/3686273.jpg                       0.0        52.000000  \n",
       "pho/163128.jpg                           25.0        58.799999  \n",
       "hot_and_sour_soup/1864685.jpg            50.0        81.599998  \n",
       "takoyaki/3609028.jpg                      0.0        59.600002  \n",
       "clam_chowder/770062.jpg                  75.0        72.800003  \n",
       "onion_rings/3494133.jpg                  25.0        63.600002  \n",
       "lobster_bisque/378185.jpg                25.0        54.799999  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 18.326104068756102\n",
      "Mean dhard_sub performance 35.0\n",
      "Mean acc_improvement 62.3200008392334\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [83.50099208567403]\n",
      "Mean accuracy across runs :  83.50099208567403\n",
      "Mean Acc for thrashed classes : 57.760000991821286\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "runs   = [\n",
    "            \"MT_Baseline_cbd6a1526138615c68153f5e5e57a692/Metrics\"\n",
    "        ]   \n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_food101_val_test_empirical_c79af0294f8e78f4a8b0793248cc788b.pkl\",\n",
    "              ]\n",
    "\n",
    "dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets/df_food101_val_test.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis for entire val set\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy']['best'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   \n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "\n",
    "df_thrashed = df_base[df_base['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>44.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>61.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>46.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>61.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>81.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>47.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>70.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>52.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>57.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  accuracy_0\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   44.400002\n",
       "beignets/847393.jpg                     Beignets      6   54.000000\n",
       "churros/274692.jpg                       Churros     23   61.600002\n",
       "sashimi/3686273.jpg                      Sashimi     86   46.400002\n",
       "pho/163128.jpg                               Pho     75   61.600002\n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   81.599998\n",
       "takoyaki/3609028.jpg                    Takoyaki     97   47.200001\n",
       "clam_chowder/770062.jpg             Clam chowder     24   70.800003\n",
       "onion_rings/3494133.jpg              Onion rings     68   52.799999\n",
       "lobster_bisque/378185.jpg         Lobster bisque     60   57.200001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base[df_base['class'].isin(thrashed_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [83.96039758814443]\n",
      "Mean accuracy across runs :  83.96039758814443\n",
      "Mean Acc for thrashed classes : 58.20000076293945\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    \"MT_Augmented_ec477f2af3db81d5b27f1ab4ed74354b/Metrics/\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>13.669065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>16.521738</td>\n",
       "      <td>50.0</td>\n",
       "      <td>57.600002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>62.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>2.985075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>16.666666</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>6.521739</td>\n",
       "      <td>25.0</td>\n",
       "      <td>80.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>6.849315</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>8.474577</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>5.607477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.600002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  dhard_accs  \\\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   13.669065   \n",
       "beignets/847393.jpg                     Beignets      6   16.521738   \n",
       "churros/274692.jpg                       Churros     23    8.333333   \n",
       "sashimi/3686273.jpg                      Sashimi     86    2.985075   \n",
       "pho/163128.jpg                               Pho     75   16.666666   \n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54    6.521739   \n",
       "takoyaki/3609028.jpg                    Takoyaki     97   15.909091   \n",
       "clam_chowder/770062.jpg             Clam chowder     24    6.849315   \n",
       "onion_rings/3494133.jpg              Onion rings     68    8.474577   \n",
       "lobster_bisque/378185.jpg         Lobster bisque     60    5.607477   \n",
       "\n",
       "                               dhard_sub_accs  accuracy_best_0  \n",
       "french_onion_soup/2993508.jpg             0.0        45.200001  \n",
       "beignets/847393.jpg                      50.0        57.600002  \n",
       "churros/274692.jpg                       25.0        62.400002  \n",
       "sashimi/3686273.jpg                       0.0        44.400002  \n",
       "pho/163128.jpg                           25.0        60.000000  \n",
       "hot_and_sour_soup/1864685.jpg            25.0        80.400002  \n",
       "takoyaki/3609028.jpg                      0.0        52.799999  \n",
       "clam_chowder/770062.jpg                  50.0        69.599998  \n",
       "onion_rings/3494133.jpg                  25.0        54.000000  \n",
       "lobster_bisque/378185.jpg                 0.0        55.600002  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 10.153807592391967\n",
      "Mean dhard_sub performance 20.0\n",
      "Mean acc_improvement 58.20000076293945\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [84.82376336579276]\n",
      "Mean accuracy across runs :  84.82376336579276\n",
      "Mean Acc for thrashed classes : 65.60000114440918\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    " \"MT_Augmented_eea97f04cc9a91db37569406512f99a1/Metrics\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>34.532375</td>\n",
       "      <td>25.0</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>20.869564</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>19.791666</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>24.626865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>19.565216</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83.200005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>25.757576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>17.808220</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.200005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>18.644068</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>18.691589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.200001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  dhard_accs  \\\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   34.532375   \n",
       "beignets/847393.jpg                     Beignets      6   20.869564   \n",
       "churros/274692.jpg                       Churros     23   19.791666   \n",
       "sashimi/3686273.jpg                      Sashimi     86   24.626865   \n",
       "pho/163128.jpg                               Pho     75   25.000000   \n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   19.565216   \n",
       "takoyaki/3609028.jpg                    Takoyaki     97   25.757576   \n",
       "clam_chowder/770062.jpg             Clam chowder     24   17.808220   \n",
       "onion_rings/3494133.jpg              Onion rings     68   18.644068   \n",
       "lobster_bisque/378185.jpg         Lobster bisque     60   18.691589   \n",
       "\n",
       "                               dhard_sub_accs  accuracy_best_0  \n",
       "french_onion_soup/2993508.jpg            25.0        62.000000  \n",
       "beignets/847393.jpg                      50.0        61.200001  \n",
       "churros/274692.jpg                       75.0        67.599998  \n",
       "sashimi/3686273.jpg                       0.0        58.400002  \n",
       "pho/163128.jpg                           25.0        68.000000  \n",
       "hot_and_sour_soup/1864685.jpg            50.0        83.200005  \n",
       "takoyaki/3609028.jpg                      0.0        60.000000  \n",
       "clam_chowder/770062.jpg                  50.0        73.200005  \n",
       "onion_rings/3494133.jpg                  50.0        61.200001  \n",
       "lobster_bisque/378185.jpg                 0.0        61.200001  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 22.528713989257813\n",
      "Mean dhard_sub performance 32.5\n",
      "Mean acc_improvement 65.60000114440918\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [84.15841727681679]\n",
      "Mean accuracy across runs :  84.15841727681679\n",
      "Mean Acc for thrashed classes : 61.7200008392334\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    \"MT_Augmented_13c4742cb456da2786183abe758579fa/Metrics\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['French onion soup','Hot and sour soup','Pho','Takoyaki', 'Churros','Beignets', 'Lobster bisque', 'Sashimi', 'Clam chowder','Onion rings']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>french_onion_soup/2993508.jpg</th>\n",
       "      <td>French onion soup</td>\n",
       "      <td>41</td>\n",
       "      <td>19.424461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beignets/847393.jpg</th>\n",
       "      <td>Beignets</td>\n",
       "      <td>6</td>\n",
       "      <td>16.521738</td>\n",
       "      <td>75.0</td>\n",
       "      <td>58.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churros/274692.jpg</th>\n",
       "      <td>Churros</td>\n",
       "      <td>23</td>\n",
       "      <td>16.666666</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sashimi/3686273.jpg</th>\n",
       "      <td>Sashimi</td>\n",
       "      <td>86</td>\n",
       "      <td>14.925373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pho/163128.jpg</th>\n",
       "      <td>Pho</td>\n",
       "      <td>75</td>\n",
       "      <td>15.624999</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot_and_sour_soup/1864685.jpg</th>\n",
       "      <td>Hot and sour soup</td>\n",
       "      <td>54</td>\n",
       "      <td>15.217391</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takoyaki/3609028.jpg</th>\n",
       "      <td>Takoyaki</td>\n",
       "      <td>97</td>\n",
       "      <td>27.272728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clam_chowder/770062.jpg</th>\n",
       "      <td>Clam chowder</td>\n",
       "      <td>24</td>\n",
       "      <td>12.328768</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onion_rings/3494133.jpg</th>\n",
       "      <td>Onion rings</td>\n",
       "      <td>68</td>\n",
       "      <td>20.338984</td>\n",
       "      <td>25.0</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobster_bisque/378185.jpg</th>\n",
       "      <td>Lobster bisque</td>\n",
       "      <td>60</td>\n",
       "      <td>8.411215</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.400002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  label  dhard_accs  \\\n",
       "french_onion_soup/2993508.jpg  French onion soup     41   19.424461   \n",
       "beignets/847393.jpg                     Beignets      6   16.521738   \n",
       "churros/274692.jpg                       Churros     23   16.666666   \n",
       "sashimi/3686273.jpg                      Sashimi     86   14.925373   \n",
       "pho/163128.jpg                               Pho     75   15.624999   \n",
       "hot_and_sour_soup/1864685.jpg  Hot and sour soup     54   15.217391   \n",
       "takoyaki/3609028.jpg                    Takoyaki     97   27.272728   \n",
       "clam_chowder/770062.jpg             Clam chowder     24   12.328768   \n",
       "onion_rings/3494133.jpg              Onion rings     68   20.338984   \n",
       "lobster_bisque/378185.jpg         Lobster bisque     60    8.411215   \n",
       "\n",
       "                               dhard_sub_accs  accuracy_best_0  \n",
       "french_onion_soup/2993508.jpg             0.0        52.400002  \n",
       "beignets/847393.jpg                      75.0        58.799999  \n",
       "churros/274692.jpg                       50.0        66.800003  \n",
       "sashimi/3686273.jpg                       0.0        52.400002  \n",
       "pho/163128.jpg                           25.0        58.799999  \n",
       "hot_and_sour_soup/1864685.jpg            50.0        80.800003  \n",
       "takoyaki/3609028.jpg                      0.0        57.200001  \n",
       "clam_chowder/770062.jpg                  75.0        71.599998  \n",
       "onion_rings/3494133.jpg                  25.0        62.000000  \n",
       "lobster_bisque/378185.jpg                25.0        56.400002  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 16.67323226928711\n",
      "Mean dhard_sub performance 32.5\n",
      "Mean acc_improvement 61.7200008392334\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
