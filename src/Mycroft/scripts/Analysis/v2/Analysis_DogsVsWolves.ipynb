{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.26666831970215]\n",
      "Mean accuracy across runs :  87.26666831970215\n",
      "Mean Acc for thrashed classes : 39.33333396911621\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs   = [\n",
    "            \"MT_Baseline_e355dad2678c98182610abce1454bad8/Metrics\"\n",
    "        ]   \n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val_empirical_71d2180577457bea97ef33317560aeb8.pkl\",\n",
    "              ]\n",
    "\n",
    "dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis for entire val set\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy']['best'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   \n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_base[df_base['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [96.44444580078125]\n",
      "Mean accuracy across runs :  96.44444580078125\n",
      "Mean Acc for thrashed classes : 85.5555534362793\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_93d9fba92fe474a88dc763b34422a76c/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>81.762924</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.666664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>68.202766</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.444443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   81.762924   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   68.202766   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...           100.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...           100.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        86.666664  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        84.444443  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 74.98284530639648\n",
      "Mean dhard_sub performance 100.0\n",
      "Mean acc_improvement 85.5555534362793\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [95.0000015258789]\n",
      "Mean accuracy across runs :  95.0000015258789\n",
      "Mean Acc for thrashed classes : 79.33333206176758\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_0a6b144d32f8fe6abf86b09af4e8abfc/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>79.027359</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.666664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>53.917049</td>\n",
       "      <td>87.5</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   79.027359   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   53.917049   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...           100.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            87.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        84.666664  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        74.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 66.47220420837402\n",
      "Mean dhard_sub performance 93.75\n",
      "Mean acc_improvement 79.33333206176758\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "93.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNICOM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [91.13333511352539]\n",
      "Mean accuracy across runs :  91.13333511352539\n",
      "Mean Acc for thrashed classes : 58.333335876464844\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_97cef2f06183c96a24bd0ad36ada735a/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>19.148937</td>\n",
       "      <td>50.0</td>\n",
       "      <td>39.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>52.995392</td>\n",
       "      <td>100.0</td>\n",
       "      <td>77.111115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   19.148937   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   52.995392   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            50.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...           100.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        39.555557  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        77.111115  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 36.07216453552246\n",
      "Mean dhard_sub performance 75.0\n",
      "Mean acc_improvement 58.333335876464844\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [92.55555725097656]\n",
      "Mean accuracy across runs :  92.55555725097656\n",
      "Mean Acc for thrashed classes : 65.77777862548828\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_0a6b144d32f8fe6abf86b09af4e8abfc/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>34.954411</td>\n",
       "      <td>62.5</td>\n",
       "      <td>51.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>58.986176</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   34.954411   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   58.986176   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            62.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...           100.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        51.555557  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        80.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 46.970293045043945\n",
      "Mean dhard_sub performance 81.25\n",
      "Mean acc_improvement 65.77777862548828\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRUPTED LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [92.0222240447998]\n",
      "Mean accuracy across runs :  92.0222240447998\n",
      "Mean Acc for thrashed classes : 63.00000190734863\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_456c4c1f0ea8af6459d6f431baa5f935/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>36.778118</td>\n",
       "      <td>87.5</td>\n",
       "      <td>52.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>47.465439</td>\n",
       "      <td>87.5</td>\n",
       "      <td>73.333336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   36.778118   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   47.465439   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            87.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            87.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        52.666668  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        73.333336  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 42.12177848815918\n",
      "Mean dhard_sub performance 87.5\n",
      "Mean acc_improvement 63.00000190734863\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.91111259460449]\n",
      "Mean accuracy across runs :  87.91111259460449\n",
      "Mean Acc for thrashed classes : 42.33333396911621\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_e2d3c7f2e630591899b2ff1ac42bc00f/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>6.686931</td>\n",
       "      <td>12.5</td>\n",
       "      <td>31.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>8.294931</td>\n",
       "      <td>25.0</td>\n",
       "      <td>52.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0    6.686931   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1    8.294931   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            12.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        31.777779  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        52.888889  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 7.490931034088135\n",
      "Mean dhard_sub performance 18.75\n",
      "Mean acc_improvement 42.33333396911621\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNICOM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [91.13333511352539]\n",
      "Mean accuracy across runs :  91.13333511352539\n",
      "Mean Acc for thrashed classes : 58.333335876464844\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_97cef2f06183c96a24bd0ad36ada735a/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>19.148937</td>\n",
       "      <td>50.0</td>\n",
       "      <td>39.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>52.995392</td>\n",
       "      <td>100.0</td>\n",
       "      <td>77.111115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   19.148937   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   52.995392   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            50.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...           100.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        39.555557  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        77.111115  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 36.07216453552246\n",
      "Mean dhard_sub performance 75.0\n",
      "Mean acc_improvement 58.333335876464844\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [91.37777976989746]\n",
      "Mean accuracy across runs :  91.37777976989746\n",
      "Mean Acc for thrashed classes : 59.777780532836914\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_c0cdb19ad440713baf0a9498a954dad9/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>28.875381</td>\n",
       "      <td>62.5</td>\n",
       "      <td>46.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>45.161289</td>\n",
       "      <td>87.5</td>\n",
       "      <td>72.888893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   28.875381   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   45.161289   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            62.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            87.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        46.666668  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        72.888893  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 37.01833534240723\n",
      "Mean dhard_sub performance 75.0\n",
      "Mean acc_improvement 59.777780532836914\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRUPTED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [92.88889083862304]\n",
      "Mean accuracy across runs :  92.88889083862304\n",
      "Mean Acc for thrashed classes : 67.55555725097656\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_5bb065f00602d5c9f9b87bb081cc8683/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>46.200611</td>\n",
       "      <td>75.0</td>\n",
       "      <td>60.222221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>48.847927</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.888893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   46.200611   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   48.847927   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            75.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...           100.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        60.222221  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        74.888893  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 47.524269104003906\n",
      "Mean dhard_sub performance 87.5\n",
      "Mean acc_improvement 67.55555725097656\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.80000152587891]\n",
      "Mean accuracy across runs :  87.80000152587891\n",
      "Mean Acc for thrashed classes : 42.0\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_dcc18063f65ca13e4d6787f917227518/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>7.902736</td>\n",
       "      <td>12.5</td>\n",
       "      <td>32.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>5.069124</td>\n",
       "      <td>25.0</td>\n",
       "      <td>51.333332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0    7.902736   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1    5.069124   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            12.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        32.666668  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        51.333332  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 6.4859299659729\n",
      "Mean dhard_sub performance 18.75\n",
      "Mean acc_improvement 42.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNICOM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [91.13333511352539]\n",
      "Mean accuracy across runs :  91.13333511352539\n",
      "Mean Acc for thrashed classes : 58.333335876464844\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>19.148937</td>\n",
       "      <td>50.0</td>\n",
       "      <td>39.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>52.995392</td>\n",
       "      <td>100.0</td>\n",
       "      <td>77.111115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   19.148937   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   52.995392   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            50.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...           100.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        39.555557  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        77.111115  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 36.07216453552246\n",
      "Mean dhard_sub performance 75.0\n",
      "Mean acc_improvement 58.333335876464844\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [91.6444465637207]\n",
      "Mean accuracy across runs :  91.6444465637207\n",
      "Mean Acc for thrashed classes : 61.222225189208984\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_2389d9924263c69d98908bbd8f5573d7/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>29.179333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>47.555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>49.308758</td>\n",
       "      <td>87.5</td>\n",
       "      <td>74.888893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   29.179333   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   49.308758   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            62.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            87.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        47.555557  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        74.888893  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 39.24404525756836\n",
      "Mean dhard_sub performance 75.0\n",
      "Mean acc_improvement 61.222225189208984\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
