{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODOS\n",
    "# need to extract weights at each training step\n",
    "# resume from checkpoint thing\n",
    "# get traceback form indices to raw training data\n",
    "# Get back form 64x64 to 224x224 sized training images\n",
    "# Add some other super lame shit features andho\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/zsarwar/data_sharing/decile/cords\")\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "os.chdir(\"/home/zsarwar/data_sharing/decile/cords\")\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from cords.utils.data.datasets.SL import gen_dataset\n",
    "from torch.utils.data import Subset\n",
    "from cords.utils.config_utils import load_config_data\n",
    "import os.path as osp\n",
    "from cords.utils.data.data_utils import WeightedSubset\n",
    "from ray import tune\n",
    "from gen_data import get_datasets\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import ResNet50_Weights, resnet18, resnet50, ResNet18_Weights\n",
    "from cords.utils.models import ResNet50, ResNet18\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "trn_batch_size = 16\n",
    "val_batch_size = 512\n",
    "tst_batch_size = 1000\n",
    "numclasses = 7\n",
    "num_epochs = 200\n",
    "print_every = 10\n",
    "save_every = 20\n",
    "data_fraction = 0.1\n",
    "select_subset_every = 2\n",
    "pretrained = False\n",
    "arch = 'ResNet18'\n",
    "\n",
    "root_save_dir = \"/bigstor/zsarwar/GradMatch\"\n",
    "config = f'DvW_Imagenet_testing_num_epochs-{num_epochs}_pretrained-{pretrained}_model-{arch}_numclasses-{numclasses}_fraction-{data_fraction}_batchsize-{trn_batch_size}_Perbatch_DvW_Pretrained'\n",
    "\n",
    "out_dir = os.path.join(root_save_dir, config)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "# Make ckpt directory\n",
    "ckpt_dir = os.path.join(out_dir, 'checkpoints')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "\n",
    "stats_path = os.path.join(out_dir, 'stats.pkl')\n",
    "\n",
    "#trainset, validset, testset, num_cls = gen_dataset('/home/zsarwar/data_sharing/decile/cords/data/', 'cifar10', None, isnumpy=False)\n",
    "\n",
    "trainset, validset, testset = get_datasets()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#trn_batch_size = 128\n",
    "#val_batch_size = 512\n",
    "#tst_batch_size = 1000\n",
    "\n",
    "# Creating the Data Loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trn_batch_size,\n",
    "                                          shuffle=False, pin_memory=True)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(validset, batch_size=val_batch_size,\n",
    "                                        shuffle=False, pin_memory=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=tst_batch_size,\n",
    "                                          shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#numclasses = 7\n",
    "device = 'cuda' #Device Argument\n",
    "\n",
    "#model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "# Change classification layer\n",
    "#model.fc = nn.Linear(in_features=512, out_features=numclasses)\n",
    "#model.embDim = 512\n",
    "#model = ResNet18()\n",
    "model = ResNet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(in_features=512, out_features=numclasses)\n",
    "\n",
    "# Add code to freeze\n",
    "\n",
    "#model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#model.maxpool = nn.Identity()\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  7.4841e-02,  5.6615e-02,\n",
      "           1.7083e-02, -1.2694e-02],\n",
      "         [ 1.1083e-02,  9.5276e-03, -1.0993e-01, -2.8050e-01, -2.7124e-01,\n",
      "          -1.2907e-01,  3.7424e-03],\n",
      "         [-6.9434e-03,  5.9089e-02,  2.9548e-01,  5.8720e-01,  5.1972e-01,\n",
      "           2.5632e-01,  6.3573e-02],\n",
      "         [ 3.0505e-02, -6.7018e-02, -2.9841e-01, -4.3868e-01, -2.7085e-01,\n",
      "          -6.1282e-04,  5.7602e-02],\n",
      "         [-2.7535e-02,  1.6045e-02,  7.2595e-02, -5.4102e-02, -3.3285e-01,\n",
      "          -4.2058e-01, -2.5781e-01],\n",
      "         [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  2.3897e-01,  4.1384e-01,\n",
      "           3.9359e-01,  1.6606e-01],\n",
      "         [-1.3736e-02, -3.6746e-03, -2.4084e-02, -6.5877e-02, -1.5070e-01,\n",
      "          -8.2230e-02, -5.7828e-03]],\n",
      "\n",
      "        [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  3.6812e-02,  3.2521e-02,\n",
      "           6.6221e-04, -2.5743e-02],\n",
      "         [ 4.5687e-02,  3.3603e-02, -1.0453e-01, -3.0885e-01, -3.1253e-01,\n",
      "          -1.6051e-01, -1.2826e-03],\n",
      "         [-8.3730e-04,  9.8420e-02,  4.0210e-01,  7.7035e-01,  7.0789e-01,\n",
      "           3.6887e-01,  1.2455e-01],\n",
      "         [-5.8427e-03, -1.2862e-01, -4.2071e-01, -5.9270e-01, -3.8285e-01,\n",
      "          -4.2407e-02,  6.1568e-02],\n",
      "         [-5.5926e-02, -5.2239e-03,  2.7081e-02, -1.5159e-01, -4.6178e-01,\n",
      "          -5.7080e-01, -3.6552e-01],\n",
      "         [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  3.1815e-01,  5.4636e-01,\n",
      "           4.8276e-01,  1.9867e-01],\n",
      "         [ 5.3051e-03,  6.6938e-03, -1.7254e-02, -6.9806e-02, -1.4822e-01,\n",
      "          -7.7248e-02,  7.2183e-04]],\n",
      "\n",
      "        [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  8.9755e-02,  8.9177e-02,\n",
      "           3.3655e-02, -2.0102e-02],\n",
      "         [ 1.5398e-02, -1.8648e-02, -1.2591e-01, -2.9553e-01, -2.5342e-01,\n",
      "          -1.2980e-01, -2.7975e-02],\n",
      "         [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  4.3010e-01,  3.4872e-01,\n",
      "           1.0433e-01,  1.8413e-02],\n",
      "         [ 2.6426e-02, -2.5990e-02, -1.9699e-01, -2.6806e-01, -1.0524e-01,\n",
      "           7.8577e-02,  1.2077e-01],\n",
      "         [-2.8356e-02,  1.8404e-02,  9.8647e-02,  6.1242e-02, -1.1740e-01,\n",
      "          -2.5760e-01, -1.5451e-01],\n",
      "         [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  5.7450e-02,  2.4141e-01,\n",
      "           2.4345e-01,  1.1796e-01],\n",
      "         [ 7.4684e-04,  7.7677e-04, -1.0050e-02, -5.5153e-02, -1.4865e-01,\n",
      "          -1.1754e-01, -3.8350e-02]]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model.named_parameters():\n",
    "    print(param[1][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.IMAGENET1K_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_state_dict() got an unexpected keyword argument 'check_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weights\u001b[39m.\u001b[39;49mget_state_dict(progress \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, check_hash\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_state_dict() got an unexpected keyword argument 'check_hash'"
     ]
    }
   ],
   "source": [
    "weights.get_state_dict(progress = True, check_hash=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
