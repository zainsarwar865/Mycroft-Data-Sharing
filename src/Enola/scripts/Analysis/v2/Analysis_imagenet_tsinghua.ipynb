{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNICOM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [81.96666666666667]\n",
      "Mean accuracy across runs :  81.96666666666667\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_Imagenet_dogs_120_44494fed02dee22a95cced5d0322a3ed\"\n",
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_Imagenet_dogs_101_637d23ae78e9c5b5ef63d577ea9250fc\"\n",
    "runs   = [\n",
    "            \"MT_Baseline_a26b2a94e3df08c066fd63cf7eb3a247/Metrics\",\n",
    "        ]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_Imagenet_dogs_120_44494fed02dee22a95cced5d0322a3ed/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_imagenet_dogs_val_test_empirical_76377e19d043d48e2d19b5b9504f33f2.pkl\",\n",
    "              ]\n",
    "\n",
    "#dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Imagenet/DF/df_imagenet_dogs_val.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "df_base['accuracy_0'].mean()\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000057.JPEG</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>107</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000078.JPEG</th>\n",
       "      <td>African hunting dog, hyena dog, Cape hunting d...</td>\n",
       "      <td>119</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000220.JPEG</th>\n",
       "      <td>pug, pug-dog</td>\n",
       "      <td>102</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000350.JPEG</th>\n",
       "      <td>Boston bull, Boston terrier</td>\n",
       "      <td>44</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000590.JPEG</th>\n",
       "      <td>Samoyed, Samoyede</td>\n",
       "      <td>106</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000883.JPEG</th>\n",
       "      <td>Bedlington terrier</td>\n",
       "      <td>30</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00001203.JPEG</th>\n",
       "      <td>Leonberg</td>\n",
       "      <td>103</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00001626.JPEG</th>\n",
       "      <td>borzoi, Russian wolfhound</td>\n",
       "      <td>18</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00002298.JPEG</th>\n",
       "      <td>Welsh springer spaniel</td>\n",
       "      <td>67</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00002708.JPEG</th>\n",
       "      <td>Bernese mountain dog</td>\n",
       "      <td>88</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          class  \\\n",
       "index                                                                             \n",
       "ILSVRC2012_val_00000057.JPEG                                         Pomeranian   \n",
       "ILSVRC2012_val_00000078.JPEG  African hunting dog, hyena dog, Cape hunting d...   \n",
       "ILSVRC2012_val_00000220.JPEG                                       pug, pug-dog   \n",
       "ILSVRC2012_val_00000350.JPEG                        Boston bull, Boston terrier   \n",
       "ILSVRC2012_val_00000590.JPEG                                  Samoyed, Samoyede   \n",
       "ILSVRC2012_val_00000883.JPEG                                 Bedlington terrier   \n",
       "ILSVRC2012_val_00001203.JPEG                                           Leonberg   \n",
       "ILSVRC2012_val_00001626.JPEG                          borzoi, Russian wolfhound   \n",
       "ILSVRC2012_val_00002298.JPEG                             Welsh springer spaniel   \n",
       "ILSVRC2012_val_00002708.JPEG                               Bernese mountain dog   \n",
       "\n",
       "                              label  accuracy_0  \n",
       "index                                            \n",
       "ILSVRC2012_val_00000057.JPEG    107        88.0  \n",
       "ILSVRC2012_val_00000078.JPEG    119       100.0  \n",
       "ILSVRC2012_val_00000220.JPEG    102        86.0  \n",
       "ILSVRC2012_val_00000350.JPEG     44        54.0  \n",
       "ILSVRC2012_val_00000590.JPEG    106        94.0  \n",
       "ILSVRC2012_val_00000883.JPEG     30        78.0  \n",
       "ILSVRC2012_val_00001203.JPEG    103        92.0  \n",
       "ILSVRC2012_val_00001626.JPEG     18        86.0  \n",
       "ILSVRC2012_val_00002298.JPEG     67        68.0  \n",
       "ILSVRC2012_val_00002708.JPEG     88        56.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = ['Welsh springer spaniel',\n",
    " 'Bedlington terrier',\n",
    " 'Pomeranian',\n",
    " 'pug, pug-dog',\n",
    " 'African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus',\n",
    " 'Bernese mountain dog',\n",
    " 'Boston bull, Boston terrier',\n",
    " 'Leonberg',\n",
    " 'Samoyed, Samoyede',\n",
    " 'borzoi, Russian wolfhound']\n",
    "\n",
    "df_base[df_base['class'].isin(cl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>accuracy_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000057.JPEG</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>107</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000078.JPEG</th>\n",
       "      <td>African hunting dog, hyena dog, Cape hunting d...</td>\n",
       "      <td>119</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000220.JPEG</th>\n",
       "      <td>pug, pug-dog</td>\n",
       "      <td>102</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000350.JPEG</th>\n",
       "      <td>Boston bull, Boston terrier</td>\n",
       "      <td>44</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000590.JPEG</th>\n",
       "      <td>Samoyed, Samoyede</td>\n",
       "      <td>106</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00000883.JPEG</th>\n",
       "      <td>Bedlington terrier</td>\n",
       "      <td>30</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00001203.JPEG</th>\n",
       "      <td>Leonberg</td>\n",
       "      <td>103</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00001626.JPEG</th>\n",
       "      <td>borzoi, Russian wolfhound</td>\n",
       "      <td>18</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00002298.JPEG</th>\n",
       "      <td>Welsh springer spaniel</td>\n",
       "      <td>67</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILSVRC2012_val_00002708.JPEG</th>\n",
       "      <td>Bernese mountain dog</td>\n",
       "      <td>88</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          class  \\\n",
       "index                                                                             \n",
       "ILSVRC2012_val_00000057.JPEG                                         Pomeranian   \n",
       "ILSVRC2012_val_00000078.JPEG  African hunting dog, hyena dog, Cape hunting d...   \n",
       "ILSVRC2012_val_00000220.JPEG                                       pug, pug-dog   \n",
       "ILSVRC2012_val_00000350.JPEG                        Boston bull, Boston terrier   \n",
       "ILSVRC2012_val_00000590.JPEG                                  Samoyed, Samoyede   \n",
       "ILSVRC2012_val_00000883.JPEG                                 Bedlington terrier   \n",
       "ILSVRC2012_val_00001203.JPEG                                           Leonberg   \n",
       "ILSVRC2012_val_00001626.JPEG                          borzoi, Russian wolfhound   \n",
       "ILSVRC2012_val_00002298.JPEG                             Welsh springer spaniel   \n",
       "ILSVRC2012_val_00002708.JPEG                               Bernese mountain dog   \n",
       "\n",
       "                              label  accuracy_0  \n",
       "index                                            \n",
       "ILSVRC2012_val_00000057.JPEG    107        98.0  \n",
       "ILSVRC2012_val_00000078.JPEG    119       100.0  \n",
       "ILSVRC2012_val_00000220.JPEG    102        98.0  \n",
       "ILSVRC2012_val_00000350.JPEG     44       100.0  \n",
       "ILSVRC2012_val_00000590.JPEG    106       100.0  \n",
       "ILSVRC2012_val_00000883.JPEG     30        98.0  \n",
       "ILSVRC2012_val_00001203.JPEG    103       100.0  \n",
       "ILSVRC2012_val_00001626.JPEG     18       100.0  \n",
       "ILSVRC2012_val_00002298.JPEG     67        98.0  \n",
       "ILSVRC2012_val_00002708.JPEG     88       100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base[df_base['class'].isin(cl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels of 10 best performing classes\n",
    "best_class_idx = df_base['accuracy_0'].sort_values()[-10:].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = df_base.loc[best_class_idx]['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welsh springer spaniel',\n",
       " 'Bedlington terrier',\n",
       " 'Pomeranian',\n",
       " 'pug, pug-dog',\n",
       " 'African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus',\n",
       " 'Bernese mountain dog',\n",
       " 'Boston bull, Boston terrier',\n",
       " 'Leonberg',\n",
       " 'Samoyed, Samoyede',\n",
       " 'borzoi, Russian wolfhound']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.44554587638024]\n",
      "Mean accuracy across runs :  87.44554587638024\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    #\"MT_Augmented_ed4e8f0db69a7ade18c9fb3337707013/Metrics\"\n",
    "    \"MT_Augmented_398b8fb6c4a73a9d6b90867598bb6ace/Metrics\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of augmented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per-class improvement is -0.18000011444091796 \n"
     ]
    }
   ],
   "source": [
    "all_emp_paths = []\n",
    "for r in dhard_runs:\n",
    "    emp_path = os.path.join(dhard_base, r)\n",
    "    all_emp_paths.append(emp_path)\n",
    "    \n",
    "all_df_emps = []\n",
    "\n",
    "for p in all_emp_paths:\n",
    "    df_emp = pd.read_pickle(p)\n",
    "    all_df_emps.append(df_emp)\n",
    "\n",
    "\n",
    "all_emp_sub_paths = []\n",
    "for r in dhard_sub_runs:\n",
    "    emp_sub_path = os.path.join(dhard_base, r)\n",
    "    all_emp_sub_paths.append(emp_sub_path)\n",
    "    \n",
    "all_df_emps_sub = []\n",
    "\n",
    "for p in all_emp_sub_paths:\n",
    "    df_emp_sub = pd.read_pickle(p)\n",
    "    all_df_emps_sub.append(df_emp_sub)\n",
    "\n",
    "\n",
    "\n",
    "all_emp_classes = []\n",
    "for i in range(len(all_df_emps)):\n",
    "    emp_classes = all_df_emps[i]['class'].unique().tolist()\n",
    "    all_emp_classes.append(emp_classes)\n",
    "\n",
    "all_acc_diffs = []\n",
    "for i in range(len(all_emp_classes)):\n",
    "    col_name_base = f\"accuracy_{i}\"\n",
    "    col_name_aug = f\"accuracy_best_{i}\"\n",
    "    col_diff = df_aug[df_aug['class'].isin(all_emp_classes[i])][col_name_aug] - df_base[df_base['class'].isin(all_emp_classes[i])][col_name_base]\n",
    "    col_diff_sum = col_diff.sum()\n",
    "    all_acc_diffs.append(col_diff_sum)\n",
    "\n",
    "res = (sum(all_acc_diffs) / len(all_acc_diffs)) / len(all_emp_classes[0])\n",
    "print(f\"Mean per-class improvement is {res} \")\n",
    "\n",
    "# Compare Dhard and Dhard_sub performances for each epoch\n",
    "all_stats_dicts = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_dicts.append(stats)\n",
    "\n",
    "base_preds = np.asarray(all_df_emps[0]['label'].to_list())\n",
    "base_preds_sub = np.asarray(all_df_emps_sub[0]['label'].to_list())\n",
    "cols = [col for col in list(all_stats_dicts[0]['predicted_labels'].keys()) if 'sub' not in col and 'best' not in col]\n",
    "\n",
    "\n",
    "for c in cols:\n",
    "    aug_preds  = np.asarray(all_stats_dicts[0]['predicted_labels'][c])\n",
    "    acc = len(np.where(aug_preds == base_preds)[0]) / len(base_preds)\n",
    "    print(f\"Acc for {c} : \", acc)\n",
    "\n",
    "\n",
    "cols = [col for col in list(all_stats_dicts[0]['predicted_labels'].keys()) if 'sub' in col]\n",
    "\n",
    "for c in cols:\n",
    "    aug_preds  = np.asarray(all_stats_dicts[0]['predicted_labels'][c])\n",
    "    acc = len(np.where(aug_preds == base_preds_sub)[0]) / len(base_preds_sub)\n",
    "    print(f\"Acc for {c} : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for 0_dhard :  0.019485580670303974\n",
      "Acc for 1_dhard :  0.03195635229929852\n",
      "Acc for 2_dhard :  0.05066250974279034\n",
      "Acc for 3_dhard :  0.07716289945440374\n",
      "Acc for 4_dhard :  0.11145752143413874\n",
      "Acc for 5_dhard :  0.1441932969602494\n",
      "Acc for 6_dhard :  0.186282151208106\n",
      "Acc for 7_dhard :  0.21200311769290725\n",
      "Acc for 8_dhard :  0.23538581449727203\n",
      "Acc for 9_dhard :  0.2564302416212003\n",
      "Acc for 0_dhard_sub :  0.018333333333333333\n",
      "Acc for 1_dhard_sub :  0.03166666666666667\n",
      "Acc for 2_dhard_sub :  0.05\n",
      "Acc for 3_dhard_sub :  0.08666666666666667\n",
      "Acc for 4_dhard_sub :  0.13166666666666665\n",
      "Acc for 5_dhard_sub :  0.165\n",
      "Acc for 6_dhard_sub :  0.20333333333333334\n",
      "Acc for 7_dhard_sub :  0.23\n",
      "Acc for 8_dhard_sub :  0.24333333333333335\n",
      "Acc for 9_dhard_sub :  0.265\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.53663514392211]\n",
      "Mean accuracy across runs :  87.53663514392211\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs   = [\n",
    "            \"MT_Baseline_8915e10296bdf7f70fb9b4bfed4f45fe/Metrics\",\n",
    "        ]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_food101_val_test_empirical_8915e10296bdf7f70fb9b4bfed4f45fe.pkl\",\n",
    "              ]\n",
    "\n",
    "dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets/df_food101_val_test.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "df_base['accuracy_0'].mean()\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.54059517737663]\n",
      "Mean accuracy across runs :  87.54059517737663\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    \"MT_Augmented_df78aa38e27467ef16f5dfbab8e0324b/Metrics\"\n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of augmented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per-class improvement is 0.12000007629394531 \n",
      "Acc for 0_dhard :  0.02260327357755261\n",
      "Acc for 1_dhard :  0.05378020265003897\n",
      "Acc for 2_dhard :  0.08573655494933749\n",
      "Acc for 3_dhard :  0.11067809820732658\n",
      "Acc for 4_dhard :  0.13172252533125486\n",
      "Acc for 5_dhard :  0.15354637568199533\n",
      "Acc for 6_dhard :  0.17069368667186283\n",
      "Acc for 7_dhard :  0.186282151208106\n",
      "Acc for 8_dhard :  0.2088854247856586\n",
      "Acc for 9_dhard :  0.2151208106001559\n",
      "Acc for 0_dhard_sub :  0.01\n",
      "Acc for 1_dhard_sub :  0.05\n",
      "Acc for 2_dhard_sub :  0.11\n",
      "Acc for 3_dhard_sub :  0.13\n",
      "Acc for 4_dhard_sub :  0.19\n",
      "Acc for 5_dhard_sub :  0.22\n",
      "Acc for 6_dhard_sub :  0.21\n",
      "Acc for 7_dhard_sub :  0.25\n",
      "Acc for 8_dhard_sub :  0.3\n",
      "Acc for 9_dhard_sub :  0.32\n"
     ]
    }
   ],
   "source": [
    "all_emp_paths = []\n",
    "for r in dhard_runs:\n",
    "    emp_path = os.path.join(dhard_base, r)\n",
    "    all_emp_paths.append(emp_path)\n",
    "    \n",
    "all_df_emps = []\n",
    "\n",
    "for p in all_emp_paths:\n",
    "    df_emp = pd.read_pickle(p)\n",
    "    all_df_emps.append(df_emp)\n",
    "\n",
    "\n",
    "all_emp_sub_paths = []\n",
    "for r in dhard_sub_runs:\n",
    "    emp_sub_path = os.path.join(dhard_base, r)\n",
    "    all_emp_sub_paths.append(emp_sub_path)\n",
    "    \n",
    "all_df_emps_sub = []\n",
    "\n",
    "for p in all_emp_sub_paths:\n",
    "    df_emp_sub = pd.read_pickle(p)\n",
    "    all_df_emps_sub.append(df_emp_sub)\n",
    "\n",
    "\n",
    "\n",
    "all_emp_classes = []\n",
    "for i in range(len(all_df_emps)):\n",
    "    emp_classes = all_df_emps[i]['class'].unique().tolist()\n",
    "    all_emp_classes.append(emp_classes)\n",
    "\n",
    "all_acc_diffs = []\n",
    "for i in range(len(all_emp_classes)):\n",
    "    col_name_base = f\"accuracy_{i}\"\n",
    "    col_name_aug = f\"accuracy_best_{i}\"\n",
    "    col_diff = df_aug[df_aug['class'].isin(all_emp_classes[i])][col_name_aug] - df_base[df_base['class'].isin(all_emp_classes[i])][col_name_base]\n",
    "    col_diff_sum = col_diff.sum()\n",
    "    all_acc_diffs.append(col_diff_sum)\n",
    "\n",
    "res = (sum(all_acc_diffs) / len(all_acc_diffs)) / len(all_emp_classes[0])\n",
    "print(f\"Mean per-class improvement is {res} \")\n",
    "\n",
    "# Compare Dhard and Dhard_sub performances for each epoch\n",
    "all_stats_dicts = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_dicts.append(stats)\n",
    "\n",
    "base_preds = np.asarray(all_df_emps[0]['label'].to_list())\n",
    "base_preds_sub = np.asarray(all_df_emps_sub[0]['label'].to_list())\n",
    "cols = [col for col in list(all_stats_dicts[0]['predicted_labels'].keys()) if 'sub' not in col and 'best' not in col]\n",
    "\n",
    "\n",
    "for c in cols:\n",
    "    aug_preds  = np.asarray(all_stats_dicts[0]['predicted_labels'][c])\n",
    "    acc = len(np.where(aug_preds == base_preds)[0]) / len(base_preds)\n",
    "    print(f\"Acc for {c} : \", acc)\n",
    "\n",
    "\n",
    "cols = [col for col in list(all_stats_dicts[0]['predicted_labels'].keys()) if 'sub' in col]\n",
    "\n",
    "for c in cols:\n",
    "    aug_preds  = np.asarray(all_stats_dicts[0]['predicted_labels'][c])\n",
    "    acc = len(np.where(aug_preds == base_preds_sub)[0]) / len(base_preds_sub)\n",
    "    print(f\"Acc for {c} : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.53663514392211]\n",
      "Mean accuracy across runs :  87.53663514392211\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs   = [\n",
    "            \"MT_Baseline_8915e10296bdf7f70fb9b4bfed4f45fe/Metrics\",\n",
    "        ]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_food101_val_test_empirical_8915e10296bdf7f70fb9b4bfed4f45fe.pkl\",\n",
    "              ]\n",
    "\n",
    "dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db/Datasets/df_food101_val_test.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "df_base['accuracy_0'].mean()\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.48118965224464]\n",
      "Mean accuracy across runs :  87.48118965224464\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_food101_full_101_f739c19e1aeeaea18c60b1bf802b05db\"\n",
    "\n",
    "runs = [\n",
    "    \"MT_Augmented_603431e9d33bb977aa03d04cb297d82c/Metrics\"    \n",
    "]\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/common_data/food_101/DF/df_food101_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of augmented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per-class improvement is 0.280000114440918 \n",
      "Acc for 0_dhard :  0.012470771628994544\n",
      "Acc for 1_dhard :  0.034294621979735\n",
      "Acc for 2_dhard :  0.06780982073265783\n",
      "Acc for 3_dhard :  0.09119251753702261\n",
      "Acc for 4_dhard :  0.10522213561964147\n",
      "Acc for 5_dhard :  0.1293842556508184\n",
      "Acc for 6_dhard :  0.15120810600155885\n",
      "Acc for 7_dhard :  0.16757599376461418\n",
      "Acc for 8_dhard :  0.18784099766173032\n",
      "Acc for 9_dhard :  0.19875292283710055\n",
      "Acc for 0_dhard_sub :  0.02\n",
      "Acc for 1_dhard_sub :  0.02\n",
      "Acc for 2_dhard_sub :  0.07\n",
      "Acc for 3_dhard_sub :  0.11\n",
      "Acc for 4_dhard_sub :  0.11\n",
      "Acc for 5_dhard_sub :  0.14\n",
      "Acc for 6_dhard_sub :  0.15\n",
      "Acc for 7_dhard_sub :  0.17\n",
      "Acc for 8_dhard_sub :  0.24\n",
      "Acc for 9_dhard_sub :  0.26\n"
     ]
    }
   ],
   "source": [
    "all_emp_paths = []\n",
    "for r in dhard_runs:\n",
    "    emp_path = os.path.join(dhard_base, r)\n",
    "    all_emp_paths.append(emp_path)\n",
    "    \n",
    "all_df_emps = []\n",
    "\n",
    "for p in all_emp_paths:\n",
    "    df_emp = pd.read_pickle(p)\n",
    "    all_df_emps.append(df_emp)\n",
    "\n",
    "\n",
    "all_emp_sub_paths = []\n",
    "for r in dhard_sub_runs:\n",
    "    emp_sub_path = os.path.join(dhard_base, r)\n",
    "    all_emp_sub_paths.append(emp_sub_path)\n",
    "    \n",
    "all_df_emps_sub = []\n",
    "\n",
    "for p in all_emp_sub_paths:\n",
    "    df_emp_sub = pd.read_pickle(p)\n",
    "    all_df_emps_sub.append(df_emp_sub)\n",
    "\n",
    "\n",
    "\n",
    "all_emp_classes = []\n",
    "for i in range(len(all_df_emps)):\n",
    "    emp_classes = all_df_emps[i]['class'].unique().tolist()\n",
    "    all_emp_classes.append(emp_classes)\n",
    "\n",
    "all_acc_diffs = []\n",
    "for i in range(len(all_emp_classes)):\n",
    "    col_name_base = f\"accuracy_{i}\"\n",
    "    col_name_aug = f\"accuracy_best_{i}\"\n",
    "    col_diff = df_aug[df_aug['class'].isin(all_emp_classes[i])][col_name_aug] - df_base[df_base['class'].isin(all_emp_classes[i])][col_name_base]\n",
    "    col_diff_sum = col_diff.sum()\n",
    "    all_acc_diffs.append(col_diff_sum)\n",
    "\n",
    "res = (sum(all_acc_diffs) / len(all_acc_diffs)) / len(all_emp_classes[0])\n",
    "print(f\"Mean per-class improvement is {res} \")\n",
    "\n",
    "# Compare Dhard and Dhard_sub performances for each epoch\n",
    "all_stats_dicts = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_dicts.append(stats)\n",
    "\n",
    "base_preds = np.asarray(all_df_emps[0]['label'].to_list())\n",
    "base_preds_sub = np.asarray(all_df_emps_sub[0]['label'].to_list())\n",
    "cols = [col for col in list(all_stats_dicts[0]['predicted_labels'].keys()) if 'sub' not in col and 'best' not in col]\n",
    "\n",
    "\n",
    "for c in cols:\n",
    "    aug_preds  = np.asarray(all_stats_dicts[0]['predicted_labels'][c])\n",
    "    acc = len(np.where(aug_preds == base_preds)[0]) / len(base_preds)\n",
    "    print(f\"Acc for {c} : \", acc)\n",
    "\n",
    "\n",
    "cols = [col for col in list(all_stats_dicts[0]['predicted_labels'].keys()) if 'sub' in col]\n",
    "\n",
    "for c in cols:\n",
    "    aug_preds  = np.asarray(all_stats_dicts[0]['predicted_labels'][c])\n",
    "    acc = len(np.where(aug_preds == base_preds_sub)[0]) / len(base_preds_sub)\n",
    "    print(f\"Acc for {c} : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
