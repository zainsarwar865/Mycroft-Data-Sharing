{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.26666831970215]\n",
      "Mean accuracy across runs :  87.26666831970215\n",
      "Mean Acc for thrashed classes : 39.33333396911621\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs   = [\n",
    "            \"MT_Baseline_e355dad2678c98182610abce1454bad8/Metrics\"\n",
    "        ]   \n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "dhard_base = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets\"\n",
    "\n",
    "dhard_runs =  [\"df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val_empirical_71d2180577457bea97ef33317560aeb8.pkl\",\n",
    "              ]\n",
    "\n",
    "dhard_sub_runs = [run.replace(\"val_test_empirical\", \"val_test_sub_empirical\") for run in dhard_runs]\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis for entire val set\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy']['best'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)\n",
    "\n",
    "df_base = df_val_classes.copy()\n",
    "\n",
    "cols = [f\"accuracy_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_base[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))   \n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_base[df_base['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [96.44444580078125]\n",
      "Mean accuracy across runs :  96.44444580078125\n",
      "Mean Acc for thrashed classes : 85.5555534362793\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_93d9fba92fe474a88dc763b34422a76c/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>81.762924</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.666664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>68.202766</td>\n",
       "      <td>75.0</td>\n",
       "      <td>84.444443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   81.762924   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   68.202766   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...           100.0   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            75.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        86.666664  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        84.444443  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 74.98284530639648\n",
      "Mean dhard_sub performance 87.5\n",
      "Mean acc_improvement 85.5555534362793\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.46666812896729]\n",
      "Mean accuracy across runs :  87.46666812896729\n",
      "Mean Acc for thrashed classes : 40.333333015441895\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_05a520b9bcd8dbe248be08a2eb94d15a/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>3.647417</td>\n",
       "      <td>12.5</td>\n",
       "      <td>28.666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>5.990784</td>\n",
       "      <td>12.5</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0    3.647417   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1    5.990784   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            12.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            12.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        28.666666  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        52.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 4.8191001415252686\n",
      "Mean dhard_sub performance 12.5\n",
      "Mean acc_improvement 40.333333015441895\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [91.46666793823242]\n",
      "Mean accuracy across runs :  91.46666793823242\n",
      "Mean Acc for thrashed classes : 60.4444465637207\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_5affa3f855786514d2250121ea9d90b7/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>29.787235</td>\n",
       "      <td>62.5</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>43.778801</td>\n",
       "      <td>62.5</td>\n",
       "      <td>72.888893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   29.787235   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   43.778801   \n",
       "\n",
       "                                                    dhard_sub_accs  \\\n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            62.5   \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            62.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        48.000000  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        72.888893  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 36.78301811218262\n",
      "Mean dhard_sub performance 62.5\n",
      "Mean acc_improvement 60.4444465637207\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.82222385406494]\n",
      "Mean accuracy across runs :  87.82222385406494\n",
      "Mean Acc for thrashed classes : 42.111111640930176\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_7c257baa26d89b7986945de13f827d9b/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>5.167173</td>\n",
       "      <td>12.5</td>\n",
       "      <td>27.555555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>13.824884</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.666668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0    5.167173  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   13.824884   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            12.5  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        27.555555  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        56.666668  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 9.496028900146484\n",
      "Mean dhard_sub performance 18.75\n",
      "Mean acc_improvement 42.111111640930176\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [88.68889045715332]\n",
      "Mean accuracy across runs :  88.68889045715332\n",
      "Mean Acc for thrashed classes : 46.11111259460449\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_2fde3986716408d5d2b6237d2a5b27f4/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>12.158055</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>15.668203</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.555557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   12.158055  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   15.668203   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            25.0  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        34.666668  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        57.555557  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 13.913129329681396\n",
      "Mean dhard_sub performance 25.0\n",
      "Mean acc_improvement 46.11111259460449\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [89.48889083862305]\n",
      "Mean accuracy across runs :  89.48889083862305\n",
      "Mean Acc for thrashed classes : 50.4444465637207\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_33f90453a422554b23074881c11221f9/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>14.285715</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>28.110600</td>\n",
       "      <td>37.5</td>\n",
       "      <td>64.888893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   14.285715  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   28.110600   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            50.0  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            37.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        36.000000  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        64.888893  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 21.19815731048584\n",
      "Mean dhard_sub performance 43.75\n",
      "Mean acc_improvement 50.4444465637207\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [90.33333435058594]\n",
      "Mean accuracy across runs :  90.33333435058594\n",
      "Mean Acc for thrashed classes : 55.11111068725586\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_1d42d09933c9977c96358b548bc4665d/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>13.981764</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>47.004608</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.444443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   13.981764  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   47.004608   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            50.0  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            75.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        35.777779  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        74.444443  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 30.493185997009277\n",
      "Mean dhard_sub performance 62.5\n",
      "Mean acc_improvement 55.11111068725586\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [87.57777919769288]\n",
      "Mean accuracy across runs :  87.57777919769288\n",
      "Mean Acc for thrashed classes : 40.666666984558105\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_f0d7deb3690663ca0681c261c87e9cfd/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>5.167173</td>\n",
       "      <td>12.5</td>\n",
       "      <td>27.555555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>12.442396</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.777779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0    5.167173  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   12.442396   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            12.5  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        27.555555  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        53.777779  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 8.804784774780273\n",
      "Mean dhard_sub performance 18.75\n",
      "Mean acc_improvement 40.666666984558105\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [88.3111125946045]\n",
      "Mean accuracy across runs :  88.3111125946045\n",
      "Mean Acc for thrashed classes : 44.22222328186035\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_592da71d346530a4c9e1b0c6addcfe50/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>11.854104</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.444447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   11.854104  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   12.903226   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            25.0  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        34.000000  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        54.444447  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 12.37866497039795\n",
      "Mean dhard_sub performance 25.0\n",
      "Mean acc_improvement 44.22222328186035\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [89.44444580078125]\n",
      "Mean accuracy across runs :  89.44444580078125\n",
      "Mean Acc for thrashed classes : 50.22222137451172\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_42c4dfcdb950302c723b4cb2a7468e0c/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>22.796354</td>\n",
       "      <td>62.5</td>\n",
       "      <td>43.333332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   22.796354  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   12.903226   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            62.5  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            25.0   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        43.333332  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        57.111111  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 17.84979009628296\n",
      "Mean dhard_sub performance 43.75\n",
      "Mean acc_improvement 50.22222137451172\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruracy for each run :  [90.91111183166504]\n",
      "Mean accuracy across runs :  90.91111183166504\n",
      "Mean Acc for thrashed classes : 57.44444465637207\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411\"\n",
    "\n",
    "runs = [\n",
    "        \"MT_Augmented_5e7249812e1d9f7514315d34cccc2980/Metrics\"\n",
    "]\n",
    "\n",
    "\n",
    "stats_filename = \"agg_class_stats.pkl\"\n",
    "\n",
    "# Load labels\n",
    "val_path = \"/bigstor/zsarwar/Enola_Augmented/MT_DogsVsWolves_full_10_70b9e2d769b9d991d57926323e355411/Datasets/df_val_MT_3_Imagenet_8_Non-Dog-wolf-animals_val.pkl\"\n",
    "\n",
    "df_val = pd.read_pickle(val_path)\n",
    "\n",
    "\n",
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_acc = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_acc.append(stats['accuracy'])\n",
    "\n",
    "df_val = df_val.drop_duplicates('label')\n",
    "df_val_classes = df_val[['class', 'label']]\n",
    "\n",
    "label_list = list(df_val_classes['label'])\n",
    "\n",
    "all_acc_list = []\n",
    "for i in range(len(all_stats_acc)):\n",
    "    accuracy_list = [all_stats_acc[i]['best'][cl] for cl in label_list]\n",
    "    all_acc_list.append(accuracy_list)\n",
    "\n",
    "for i in range(len(all_acc_list)):\n",
    "    col_name = f\"accuracy_best_{i}\"\n",
    "    df_val_classes.insert(2, col_name, all_acc_list[i], True)   \n",
    "\n",
    "df_aug = df_val_classes.copy()\n",
    "cols = [f\"accuracy_best_{i}\" for i in range(len(all_acc_list))]\n",
    "mean_accs = []\n",
    "for c in cols:\n",
    "    t_acc = df_aug[c].mean()\n",
    "    mean_accs.append(t_acc)\n",
    "print(\"Accruracy for each run : \", mean_accs)\n",
    "mean_accs = np.asarray(mean_accs)\n",
    "print(\"Mean accuracy across runs : \", np.mean(mean_accs))\n",
    "\n",
    "\n",
    "\n",
    "thrashed_classes = ['dogs', 'wolves']\n",
    "df_thrashed = df_aug[df_aug['class'].isin(thrashed_classes)]\n",
    "\n",
    "for c in cols:\n",
    "    print(f\"Mean Acc for thrashed classes : {df_thrashed[c].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of DHard and DHard_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start analysis\n",
    "all_stats_paths = []\n",
    "for r in runs:\n",
    "    stats_path = os.path.join(base_dir, r, stats_filename)\n",
    "    all_stats_paths.append(stats_path)\n",
    "    \n",
    "all_stats_accs_dhard = []\n",
    "all_stats_accs_dhard_sub = []\n",
    "for path in all_stats_paths:\n",
    "    stats = pd.read_pickle(path)\n",
    "    all_stats_accs_dhard.append(stats['accuracy']['dhard_best'])\n",
    "    all_stats_accs_dhard_sub.append(stats['accuracy']['dhard_sub_best'])\n",
    "\n",
    "dhard_accs = list(all_stats_accs_dhard[0].values()) \n",
    "dhard_sub_accs = list(all_stats_accs_dhard_sub[0].values()) \n",
    "new_cols = [dhard_accs, dhard_sub_accs]\n",
    "df_thrashed.insert(2, 'dhard_accs', dhard_accs)\n",
    "df_thrashed.insert(3, 'dhard_sub_accs', dhard_sub_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "      <th>dhard_accs</th>\n",
       "      <th>dhard_sub_accs</th>\n",
       "      <th>accuracy_best_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolves_adversarial_Dogs_vs_Wolves_Arcticwolfongrass_488.jpg</th>\n",
       "      <td>wolves</td>\n",
       "      <td>0</td>\n",
       "      <td>23.100306</td>\n",
       "      <td>62.5</td>\n",
       "      <td>43.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamuteplayingonsnow_304.jpg</th>\n",
       "      <td>dogs</td>\n",
       "      <td>1</td>\n",
       "      <td>41.474655</td>\n",
       "      <td>62.5</td>\n",
       "      <td>71.777779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     class  label  dhard_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...  wolves      0   23.100306  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...    dogs      1   41.474655   \n",
       "\n",
       "                                                    dhard_sub_accs   \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...            62.5  \\\n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...            62.5   \n",
       "\n",
       "                                                    accuracy_best_0  \n",
       "wolves_adversarial_Dogs_vs_Wolves_Arcticwolfong...        43.111111  \n",
       "dogs_adversarial_Dogs_vs_Wolves_Alaskanmalamute...        71.777779  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thrashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dhard performance 32.28748035430908\n",
      "Mean dhard_sub performance 62.5\n",
      "Mean acc_improvement 57.44444465637207\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean dhard performance\", df_thrashed['dhard_accs'].mean())\n",
    "print(\"Mean dhard_sub performance\", df_thrashed['dhard_sub_accs'].mean())\n",
    "print(\"Mean acc_improvement\", df_thrashed['accuracy_best_0'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
